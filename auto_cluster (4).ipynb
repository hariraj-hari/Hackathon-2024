{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c613895-c1a6-46d2-8a63-62039f258e54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679c05fd-b556-4190-83c4-3c3881e53b48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(\"C:\\\\Users\\\\aravi\\\\OneDrive\\\\Documents\\\\problem_statement_1_and_2\\\\no_pii_grievance\\\\no_pii_grievance.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7813b6c-2cc7-49d4-93a6-89f3a3f5b603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>CategoryV7</th>\n",
       "      <th>DiaryDate</th>\n",
       "      <th>UserCode</th>\n",
       "      <th>closing_date</th>\n",
       "      <th>dist_name</th>\n",
       "      <th>org_code</th>\n",
       "      <th>pincode</th>\n",
       "      <th>recvd_date</th>\n",
       "      <th>registration_no</th>\n",
       "      <th>remarks_text</th>\n",
       "      <th>resolution_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>state</th>\n",
       "      <th>subject_content_text</th>\n",
       "      <th>v7_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MORLY/E/2023/0000001</td>\n",
       "      <td>11578.0</td>\n",
       "      <td>2023-01-01T00:00:19.977+0000</td>\n",
       "      <td>110124.0</td>\n",
       "      <td>2023-01-04T00:00:00.000+0000</td>\n",
       "      <td>North 24 Parganas</td>\n",
       "      <td>MORLY</td>\n",
       "      <td>700130</td>\n",
       "      <td>2023-01-01T00:00:19.977+0000</td>\n",
       "      <td>MORLY/E/2023/0000001</td>\n",
       "      <td>As per railway record,  there is no authoriz...</td>\n",
       "      <td>2023-01-04T00:00:00.000+0000</td>\n",
       "      <td>M</td>\n",
       "      <td>WB</td>\n",
       "      <td>Railways, ( Railway Board) &gt;&gt; Miscellaneous\\r\\...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOVUP/E/2023/0000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-01T00:01:29.780+0000</td>\n",
       "      <td>45427.0</td>\n",
       "      <td>2023-01-24T00:00:00.000+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GOVUP</td>\n",
       "      <td>203001</td>\n",
       "      <td>2023-01-01T00:01:28.567+0000</td>\n",
       "      <td>GOVUP/E/2023/0000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>UP</td>\n",
       "      <td>DARPG/E/2022/44090\\tREGARDING CBCID INSPECTION...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MOLBR/E/2023/0000001</td>\n",
       "      <td>2369.0</td>\n",
       "      <td>2023-01-01T00:01:45.593+0000</td>\n",
       "      <td>1356254.0</td>\n",
       "      <td>2023-01-12T00:00:00.000+0000</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>MOLBR</td>\n",
       "      <td>500023</td>\n",
       "      <td>2023-01-01T00:01:45.593+0000</td>\n",
       "      <td>MOLBR/E/2023/0000001</td>\n",
       "      <td>Sir/Madam, With reference to Grievance no. MO...</td>\n",
       "      <td>2023-01-12T00:00:00.000+0000</td>\n",
       "      <td>M</td>\n",
       "      <td>TG</td>\n",
       "      <td>Labour and Employment &gt;&gt; PF Withdrawal &gt;&gt; Othe...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MOLBR/E/2023/0000002</td>\n",
       "      <td>2379.0</td>\n",
       "      <td>2023-01-01T00:02:07.247+0000</td>\n",
       "      <td>1092136.0</td>\n",
       "      <td>2023-01-06T00:00:00.000+0000</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>MOLBR</td>\n",
       "      <td>440001</td>\n",
       "      <td>2023-01-01T00:02:07.247+0000</td>\n",
       "      <td>MOLBR/E/2023/0000002</td>\n",
       "      <td>Please submit establishment clarification let...</td>\n",
       "      <td>2023-01-06T00:00:00.000+0000</td>\n",
       "      <td>M</td>\n",
       "      <td>MH</td>\n",
       "      <td>Labour and Employment &gt;&gt; Pension &gt;&gt; Others\\r\\n...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOVUP/E/2023/0000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-01T00:02:25.663+0000</td>\n",
       "      <td>45427.0</td>\n",
       "      <td>2023-01-24T00:00:00.000+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GOVUP</td>\n",
       "      <td>203001</td>\n",
       "      <td>2023-01-01T00:02:24.913+0000</td>\n",
       "      <td>GOVUP/E/2023/0000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>UP</td>\n",
       "      <td>DARPG/E/2022/44088\\tREGARDING CBCID INSPECTION...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175779</th>\n",
       "      <td>UIDAI/E/2023/0001182</td>\n",
       "      <td>7753.0</td>\n",
       "      <td>2023-01-31T23:55:14.960+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-01T00:00:00.000+0000</td>\n",
       "      <td>Pakaur</td>\n",
       "      <td>UIDAI</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-01-31T23:55:14.960+0000</td>\n",
       "      <td>UIDAI/E/2023/0001182</td>\n",
       "      <td>Dear Resident ,\\r\\nPlease register your compl...</td>\n",
       "      <td>2023-02-01T00:00:00.000+0000</td>\n",
       "      <td>M</td>\n",
       "      <td>JH</td>\n",
       "      <td>मै  एक csc e gov. का एक साधारण vle हूँ, मैंने ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175780</th>\n",
       "      <td>DPOST/E/2023/0004221</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2023-01-31T23:55:47.873+0000</td>\n",
       "      <td>785742.0</td>\n",
       "      <td>2023-02-03T00:00:00.000+0000</td>\n",
       "      <td>Cuttack</td>\n",
       "      <td>DPOST</td>\n",
       "      <td>753001</td>\n",
       "      <td>2023-01-31T23:55:47.873+0000</td>\n",
       "      <td>DPOST/E/2023/0004221</td>\n",
       "      <td>Sir,\\r\\n This Article is delivered on dated 25...</td>\n",
       "      <td>2023-02-03T00:00:00.000+0000</td>\n",
       "      <td>M</td>\n",
       "      <td>OR</td>\n",
       "      <td>Posts &gt;&gt; Delay/ Non - Delivery/Abstraction of ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175781</th>\n",
       "      <td>MOMAF/E/2023/0000235</td>\n",
       "      <td>10024.0</td>\n",
       "      <td>2023-01-31T23:56:36.113+0000</td>\n",
       "      <td>14256.0</td>\n",
       "      <td>2023-02-01T00:00:00.000+0000</td>\n",
       "      <td>Anantnag</td>\n",
       "      <td>MOMAF</td>\n",
       "      <td>192212</td>\n",
       "      <td>2023-01-31T23:56:36.113+0000</td>\n",
       "      <td>MOMAF/E/2023/0000235</td>\n",
       "      <td>This Ministry appreciate the concerns of all ...</td>\n",
       "      <td>2023-02-01T00:00:00.000+0000</td>\n",
       "      <td>M</td>\n",
       "      <td>JK</td>\n",
       "      <td>Minority Affairs &gt;&gt; Maulana Azad National Fell...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175782</th>\n",
       "      <td>MOLBR/E/2023/0010864</td>\n",
       "      <td>2378.0</td>\n",
       "      <td>2023-01-31T23:59:36.513+0000</td>\n",
       "      <td>1722766.0</td>\n",
       "      <td>2023-02-03T00:00:00.000+0000</td>\n",
       "      <td>Mumbai City</td>\n",
       "      <td>MOLBR</td>\n",
       "      <td>400049</td>\n",
       "      <td>2023-01-31T23:59:36.513+0000</td>\n",
       "      <td>MOLBR/E/2023/0010864</td>\n",
       "      <td>Sir/Madam, you are hereby advised to apply fo...</td>\n",
       "      <td>2023-02-02T00:00:00.000+0000</td>\n",
       "      <td>F</td>\n",
       "      <td>MH</td>\n",
       "      <td>Labour and Employment &gt;&gt; Pension &gt;&gt; Transfer i...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175783</th>\n",
       "      <td>MODEF/E/2023/0000652</td>\n",
       "      <td>7205.0</td>\n",
       "      <td>2023-01-31T23:59:49.710+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Bhagalpur</td>\n",
       "      <td>MODEF</td>\n",
       "      <td>813209</td>\n",
       "      <td>2023-01-31T23:59:49.710+0000</td>\n",
       "      <td>MODEF/E/2023/0000652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>BH</td>\n",
       "      <td>शिकायत सन्दर्भ संख्या MODEF/E/2013/00505\\r\\nके...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175784 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         _id  CategoryV7                     DiaryDate  \\\n",
       "0       MORLY/E/2023/0000001     11578.0  2023-01-01T00:00:19.977+0000   \n",
       "1       GOVUP/E/2023/0000001         NaN  2023-01-01T00:01:29.780+0000   \n",
       "2       MOLBR/E/2023/0000001      2369.0  2023-01-01T00:01:45.593+0000   \n",
       "3       MOLBR/E/2023/0000002      2379.0  2023-01-01T00:02:07.247+0000   \n",
       "4       GOVUP/E/2023/0000002         NaN  2023-01-01T00:02:25.663+0000   \n",
       "...                      ...         ...                           ...   \n",
       "175779  UIDAI/E/2023/0001182      7753.0  2023-01-31T23:55:14.960+0000   \n",
       "175780  DPOST/E/2023/0004221        77.0  2023-01-31T23:55:47.873+0000   \n",
       "175781  MOMAF/E/2023/0000235     10024.0  2023-01-31T23:56:36.113+0000   \n",
       "175782  MOLBR/E/2023/0010864      2378.0  2023-01-31T23:59:36.513+0000   \n",
       "175783  MODEF/E/2023/0000652      7205.0  2023-01-31T23:59:49.710+0000   \n",
       "\n",
       "         UserCode                  closing_date          dist_name org_code  \\\n",
       "0        110124.0  2023-01-04T00:00:00.000+0000  North 24 Parganas    MORLY   \n",
       "1         45427.0  2023-01-24T00:00:00.000+0000                NaN    GOVUP   \n",
       "2       1356254.0  2023-01-12T00:00:00.000+0000          Hyderabad    MOLBR   \n",
       "3       1092136.0  2023-01-06T00:00:00.000+0000             Nagpur    MOLBR   \n",
       "4         45427.0  2023-01-24T00:00:00.000+0000                NaN    GOVUP   \n",
       "...           ...                           ...                ...      ...   \n",
       "175779        NaN  2023-02-01T00:00:00.000+0000             Pakaur    UIDAI   \n",
       "175780   785742.0  2023-02-03T00:00:00.000+0000            Cuttack    DPOST   \n",
       "175781    14256.0  2023-02-01T00:00:00.000+0000           Anantnag    MOMAF   \n",
       "175782  1722766.0  2023-02-03T00:00:00.000+0000        Mumbai City    MOLBR   \n",
       "175783        NaN                          None          Bhagalpur    MODEF   \n",
       "\n",
       "       pincode                    recvd_date       registration_no  \\\n",
       "0       700130  2023-01-01T00:00:19.977+0000  MORLY/E/2023/0000001   \n",
       "1       203001  2023-01-01T00:01:28.567+0000  GOVUP/E/2023/0000001   \n",
       "2       500023  2023-01-01T00:01:45.593+0000  MOLBR/E/2023/0000001   \n",
       "3       440001  2023-01-01T00:02:07.247+0000  MOLBR/E/2023/0000002   \n",
       "4       203001  2023-01-01T00:02:24.913+0000  GOVUP/E/2023/0000002   \n",
       "...        ...                           ...                   ...   \n",
       "175779    None  2023-01-31T23:55:14.960+0000  UIDAI/E/2023/0001182   \n",
       "175780  753001  2023-01-31T23:55:47.873+0000  DPOST/E/2023/0004221   \n",
       "175781  192212  2023-01-31T23:56:36.113+0000  MOMAF/E/2023/0000235   \n",
       "175782  400049  2023-01-31T23:59:36.513+0000  MOLBR/E/2023/0010864   \n",
       "175783  813209  2023-01-31T23:59:49.710+0000  MODEF/E/2023/0000652   \n",
       "\n",
       "                                             remarks_text  \\\n",
       "0         As per railway record,  there is no authoriz...   \n",
       "1                                                     NaN   \n",
       "2        Sir/Madam, With reference to Grievance no. MO...   \n",
       "3        Please submit establishment clarification let...   \n",
       "4                                                     NaN   \n",
       "...                                                   ...   \n",
       "175779   Dear Resident ,\\r\\nPlease register your compl...   \n",
       "175780  Sir,\\r\\n This Article is delivered on dated 25...   \n",
       "175781   This Ministry appreciate the concerns of all ...   \n",
       "175782   Sir/Madam, you are hereby advised to apply fo...   \n",
       "175783                                                NaN   \n",
       "\n",
       "                     resolution_date sex state  \\\n",
       "0       2023-01-04T00:00:00.000+0000   M    WB   \n",
       "1                                NaN   M    UP   \n",
       "2       2023-01-12T00:00:00.000+0000   M    TG   \n",
       "3       2023-01-06T00:00:00.000+0000   M    MH   \n",
       "4                                NaN   M    UP   \n",
       "...                              ...  ..   ...   \n",
       "175779  2023-02-01T00:00:00.000+0000   M    JH   \n",
       "175780  2023-02-03T00:00:00.000+0000   M    OR   \n",
       "175781  2023-02-01T00:00:00.000+0000   M    JK   \n",
       "175782  2023-02-02T00:00:00.000+0000   F    MH   \n",
       "175783                           NaN   M    BH   \n",
       "\n",
       "                                     subject_content_text v7_target  \n",
       "0       Railways, ( Railway Board) >> Miscellaneous\\r\\...        No  \n",
       "1       DARPG/E/2022/44090\\tREGARDING CBCID INSPECTION...       NaN  \n",
       "2       Labour and Employment >> PF Withdrawal >> Othe...        No  \n",
       "3       Labour and Employment >> Pension >> Others\\r\\n...        No  \n",
       "4       DARPG/E/2022/44088\\tREGARDING CBCID INSPECTION...       NaN  \n",
       "...                                                   ...       ...  \n",
       "175779  मै  एक csc e gov. का एक साधारण vle हूँ, मैंने ...        No  \n",
       "175780  Posts >> Delay/ Non - Delivery/Abstraction of ...        No  \n",
       "175781  Minority Affairs >> Maulana Azad National Fell...       Yes  \n",
       "175782  Labour and Employment >> Pension >> Transfer i...        No  \n",
       "175783  शिकायत सन्दर्भ संख्या MODEF/E/2013/00505\\r\\nके...       Yes  \n",
       "\n",
       "[175784 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8867de8f-0b7d-487c-ab11-cdba882aaf92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>CategoryV7</th>\n",
       "      <th>DiaryDate</th>\n",
       "      <th>UserCode</th>\n",
       "      <th>closing_date</th>\n",
       "      <th>dist_name</th>\n",
       "      <th>org_code</th>\n",
       "      <th>pincode</th>\n",
       "      <th>recvd_date</th>\n",
       "      <th>registration_no</th>\n",
       "      <th>remarks_text</th>\n",
       "      <th>resolution_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>state</th>\n",
       "      <th>subject_content_text</th>\n",
       "      <th>v7_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MORLY/E/2023/0000001</td>\n",
       "      <td>11578.0</td>\n",
       "      <td>2023-01-01T00:00:19.977+0000</td>\n",
       "      <td>110124.0</td>\n",
       "      <td>2023-01-04T00:00:00.000+0000</td>\n",
       "      <td>North 24 Parganas</td>\n",
       "      <td>MORLY</td>\n",
       "      <td>700130</td>\n",
       "      <td>2023-01-01T00:00:19.977+0000</td>\n",
       "      <td>MORLY/E/2023/0000001</td>\n",
       "      <td>As per railway record,  there is no authoriz...</td>\n",
       "      <td>2023-01-04T00:00:00.000+0000</td>\n",
       "      <td>M</td>\n",
       "      <td>WB</td>\n",
       "      <td>Railways, ( Railway Board) &gt;&gt; Miscellaneous\\r\\...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOVUP/E/2023/0000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-01T00:01:29.780+0000</td>\n",
       "      <td>45427.0</td>\n",
       "      <td>2023-01-24T00:00:00.000+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GOVUP</td>\n",
       "      <td>203001</td>\n",
       "      <td>2023-01-01T00:01:28.567+0000</td>\n",
       "      <td>GOVUP/E/2023/0000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>UP</td>\n",
       "      <td>DARPG/E/2022/44090\\tREGARDING CBCID INSPECTION...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MOLBR/E/2023/0000001</td>\n",
       "      <td>2369.0</td>\n",
       "      <td>2023-01-01T00:01:45.593+0000</td>\n",
       "      <td>1356254.0</td>\n",
       "      <td>2023-01-12T00:00:00.000+0000</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>MOLBR</td>\n",
       "      <td>500023</td>\n",
       "      <td>2023-01-01T00:01:45.593+0000</td>\n",
       "      <td>MOLBR/E/2023/0000001</td>\n",
       "      <td>Sir/Madam, With reference to Grievance no. MO...</td>\n",
       "      <td>2023-01-12T00:00:00.000+0000</td>\n",
       "      <td>M</td>\n",
       "      <td>TG</td>\n",
       "      <td>Labour and Employment &gt;&gt; PF Withdrawal &gt;&gt; Othe...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MOLBR/E/2023/0000002</td>\n",
       "      <td>2379.0</td>\n",
       "      <td>2023-01-01T00:02:07.247+0000</td>\n",
       "      <td>1092136.0</td>\n",
       "      <td>2023-01-06T00:00:00.000+0000</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>MOLBR</td>\n",
       "      <td>440001</td>\n",
       "      <td>2023-01-01T00:02:07.247+0000</td>\n",
       "      <td>MOLBR/E/2023/0000002</td>\n",
       "      <td>Please submit establishment clarification let...</td>\n",
       "      <td>2023-01-06T00:00:00.000+0000</td>\n",
       "      <td>M</td>\n",
       "      <td>MH</td>\n",
       "      <td>Labour and Employment &gt;&gt; Pension &gt;&gt; Others\\r\\n...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOVUP/E/2023/0000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-01T00:02:25.663+0000</td>\n",
       "      <td>45427.0</td>\n",
       "      <td>2023-01-24T00:00:00.000+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GOVUP</td>\n",
       "      <td>203001</td>\n",
       "      <td>2023-01-01T00:02:24.913+0000</td>\n",
       "      <td>GOVUP/E/2023/0000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>UP</td>\n",
       "      <td>DARPG/E/2022/44088\\tREGARDING CBCID INSPECTION...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    _id  CategoryV7                     DiaryDate   UserCode  \\\n",
       "0  MORLY/E/2023/0000001     11578.0  2023-01-01T00:00:19.977+0000   110124.0   \n",
       "1  GOVUP/E/2023/0000001         NaN  2023-01-01T00:01:29.780+0000    45427.0   \n",
       "2  MOLBR/E/2023/0000001      2369.0  2023-01-01T00:01:45.593+0000  1356254.0   \n",
       "3  MOLBR/E/2023/0000002      2379.0  2023-01-01T00:02:07.247+0000  1092136.0   \n",
       "4  GOVUP/E/2023/0000002         NaN  2023-01-01T00:02:25.663+0000    45427.0   \n",
       "\n",
       "                   closing_date          dist_name org_code pincode  \\\n",
       "0  2023-01-04T00:00:00.000+0000  North 24 Parganas    MORLY  700130   \n",
       "1  2023-01-24T00:00:00.000+0000                NaN    GOVUP  203001   \n",
       "2  2023-01-12T00:00:00.000+0000          Hyderabad    MOLBR  500023   \n",
       "3  2023-01-06T00:00:00.000+0000             Nagpur    MOLBR  440001   \n",
       "4  2023-01-24T00:00:00.000+0000                NaN    GOVUP  203001   \n",
       "\n",
       "                     recvd_date       registration_no  \\\n",
       "0  2023-01-01T00:00:19.977+0000  MORLY/E/2023/0000001   \n",
       "1  2023-01-01T00:01:28.567+0000  GOVUP/E/2023/0000001   \n",
       "2  2023-01-01T00:01:45.593+0000  MOLBR/E/2023/0000001   \n",
       "3  2023-01-01T00:02:07.247+0000  MOLBR/E/2023/0000002   \n",
       "4  2023-01-01T00:02:24.913+0000  GOVUP/E/2023/0000002   \n",
       "\n",
       "                                        remarks_text  \\\n",
       "0    As per railway record,  there is no authoriz...   \n",
       "1                                                NaN   \n",
       "2   Sir/Madam, With reference to Grievance no. MO...   \n",
       "3   Please submit establishment clarification let...   \n",
       "4                                                NaN   \n",
       "\n",
       "                resolution_date sex state  \\\n",
       "0  2023-01-04T00:00:00.000+0000   M    WB   \n",
       "1                           NaN   M    UP   \n",
       "2  2023-01-12T00:00:00.000+0000   M    TG   \n",
       "3  2023-01-06T00:00:00.000+0000   M    MH   \n",
       "4                           NaN   M    UP   \n",
       "\n",
       "                                subject_content_text v7_target  \n",
       "0  Railways, ( Railway Board) >> Miscellaneous\\r\\...        No  \n",
       "1  DARPG/E/2022/44090\\tREGARDING CBCID INSPECTION...       NaN  \n",
       "2  Labour and Employment >> PF Withdrawal >> Othe...        No  \n",
       "3  Labour and Employment >> Pension >> Others\\r\\n...        No  \n",
       "4  DARPG/E/2022/44088\\tREGARDING CBCID INSPECTION...       NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aad0e42e-83f9-4129-8204-b3e7947131a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Railways, ( Railway Board) >> Miscellaneous\\r\\n\\r\\nRailway Board/ Zone/ PSU/ PU/ Office : Railway Board - Railway Board\\r\\n-----------------------\\r\\nTo\\r\\nThe Railway Board\\r\\nSDAH  ER\\r\\n\\r\\nLocation   Madhyamgram\\r\\n\\r\\nI  further to informing you that the temporary railway line crossing near Madhyamgram station  BT end.  is in a very bad condition. The stones on the side of the line have been moved far enough to cause great danger to the yrain,common people and train passengers at any time. Please look at the matter.  Although it was said that the place will be fixed but not done!\\r\\nThanking you\\r\\nYours truly\\r\\nBhaskar  Mitra\\r\\n1.1.2023'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subject_content_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9065c690-3a22-4240-8ce9-471507bc451a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_13244\\1631866914.py:4: FutureWarning: Possible set difference at position 11\n",
      "  cleaned_text = re.sub(regex_pattern, ' ', text)\n",
      "C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_13244\\1631866914.py:4: FutureWarning: Possible set difference at position 13\n",
      "  cleaned_text = re.sub(regex_pattern, ' ', text)\n",
      "C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_13244\\1631866914.py:4: FutureWarning: Possible set difference at position 14\n",
      "  cleaned_text = re.sub(regex_pattern, ' ', text)\n",
      "C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_13244\\1631866914.py:4: FutureWarning: Possible set difference at position 16\n",
      "  cleaned_text = re.sub(regex_pattern, ' ', text)\n",
      "C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_13244\\1631866914.py:4: FutureWarning: Possible set difference at position 17\n",
      "  cleaned_text = re.sub(regex_pattern, ' ', text)\n",
      "C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_13244\\1631866914.py:4: FutureWarning: Possible set difference at position 19\n",
      "  cleaned_text = re.sub(regex_pattern, ' ', text)\n",
      "C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_13244\\1631866914.py:4: FutureWarning: Possible set difference at position 20\n",
      "  cleaned_text = re.sub(regex_pattern, ' ', text)\n",
      "C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_13244\\1631866914.py:4: FutureWarning: Possible set difference at position 22\n",
      "  cleaned_text = re.sub(regex_pattern, ' ', text)\n",
      "C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_13244\\1631866914.py:4: FutureWarning: Possible set difference at position 23\n",
      "  cleaned_text = re.sub(regex_pattern, ' ', text)\n",
      "C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_13244\\1631866914.py:4: FutureWarning: Possible set difference at position 25\n",
      "  cleaned_text = re.sub(regex_pattern, ' ', text)\n",
      "C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_13244\\1631866914.py:4: FutureWarning: Possible set difference at position 26\n",
      "  cleaned_text = re.sub(regex_pattern, ' ', text)\n",
      "C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_13244\\1631866914.py:4: FutureWarning: Possible set difference at position 28\n",
      "  cleaned_text = re.sub(regex_pattern, ' ', text)\n",
      "C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_13244\\1631866914.py:4: FutureWarning: Possible set difference at position 29\n",
      "  cleaned_text = re.sub(regex_pattern, ' ', text)\n",
      "C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_13244\\1631866914.py:4: FutureWarning: Possible set difference at position 31\n",
      "  cleaned_text = re.sub(regex_pattern, ' ', text)\n",
      "C:\\Users\\aravi\\AppData\\Local\\Temp\\ipykernel_13244\\1631866914.py:4: FutureWarning: Possible set difference at position 32\n",
      "  cleaned_text = re.sub(regex_pattern, ' ', text)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         Railways Railway Board Miscellaneous Railway B...\n",
       "1         DARPG E REGARDING CBCID INSPECTION closed on w...\n",
       "2         Labour and Employment PF Withdrawal Others Nam...\n",
       "3         Labour and Employment Pension Others Name and ...\n",
       "4         DARPG E REGARDING CBCID INSPECTION closed on w...\n",
       "                                ...                        \n",
       "175779    मै एक csc e gov का एक साधारण vle हूँ मैंने आधा...\n",
       "175780    Posts Delay Non Delivery Abstraction of Postal...\n",
       "175781    Minority Affairs Maulana Azad National Fellows...\n",
       "175782    Labour and Employment Pension Transfer in not ...\n",
       "175783    शिकायत सन्दर्भ संख्या MODEF E के मामले में अब ...\n",
       "Name: subject_content_text, Length: 175784, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "regex_pattern = r'[()>>\\r\\n\\r-----------------------\\0-9x x x x x X X X X X]'\n",
    "def clean_subject_content_text(text):\n",
    "    cleaned_text = re.sub(regex_pattern, ' ', text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the clean_subject_content_text function to the subject_content_text column\n",
    "df['subject_content_text'] = df['subject_content_text'].apply(clean_subject_content_text)\n",
    "\n",
    "# Output the cleaned DataFrame\n",
    "df['subject_content_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a972978-bd85-4b4c-a941-5bc146d52a09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\aravi\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\aravi\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\aravi\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\aravi\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aravi\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aravi\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a39a5138-b959-4774-8e04-8809fe3b211d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d2ffd4f-2a44-4334-bf3f-2ca9ac5d369c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    # Define the punctuation marks to remove\n",
    "    punctuation_marks = string.punctuation\n",
    "    # Remove punctuation marks\n",
    "    text_without_punctuation = ''.join([char for char in text if char not in punctuation_marks])\n",
    "    return text_without_punctuation\n",
    "\n",
    "# Apply punctuation handling to the DataFrame column\n",
    "df['modified_text'] = df['subject_content_text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f100e57c-c4de-44e7-a59f-efd946b8cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d394440-ecc8-471d-b8d3-1d387f56b8ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "439ca375-aa20-48ff-9232-2f6084463cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize as wtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8541b4d-225d-4dd8-989f-b733aecfc7d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['modified_text']=df['modified_text'].apply(lambda x : wtk(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7688b24-74cd-48d0-abaa-416cbcabbf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Railways',\n",
       " 'Railway',\n",
       " 'Board',\n",
       " 'Miscellaneous',\n",
       " 'Railway',\n",
       " 'Board',\n",
       " 'Zone',\n",
       " 'PSU',\n",
       " 'PU',\n",
       " 'Office',\n",
       " 'Railway',\n",
       " 'Board',\n",
       " 'Railway',\n",
       " 'Board',\n",
       " 'To',\n",
       " 'The',\n",
       " 'Railway',\n",
       " 'Board',\n",
       " 'SDAH',\n",
       " 'ER',\n",
       " 'Location',\n",
       " 'Madhyamgram',\n",
       " 'I',\n",
       " 'further',\n",
       " 'to',\n",
       " 'informing',\n",
       " 'you',\n",
       " 'that',\n",
       " 'the',\n",
       " 'temporary',\n",
       " 'railway',\n",
       " 'line',\n",
       " 'crossing',\n",
       " 'near',\n",
       " 'Madhyamgram',\n",
       " 'station',\n",
       " 'BT',\n",
       " 'end',\n",
       " 'is',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'bad',\n",
       " 'condition',\n",
       " 'The',\n",
       " 'stones',\n",
       " 'on',\n",
       " 'the',\n",
       " 'side',\n",
       " 'of',\n",
       " 'the',\n",
       " 'line',\n",
       " 'have',\n",
       " 'been',\n",
       " 'moved',\n",
       " 'far',\n",
       " 'enough',\n",
       " 'to',\n",
       " 'cause',\n",
       " 'great',\n",
       " 'danger',\n",
       " 'to',\n",
       " 'the',\n",
       " 'yrain',\n",
       " 'common',\n",
       " 'people',\n",
       " 'and',\n",
       " 'train',\n",
       " 'passengers',\n",
       " 'at',\n",
       " 'any',\n",
       " 'time',\n",
       " 'Please',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'matter',\n",
       " 'Although',\n",
       " 'it',\n",
       " 'was',\n",
       " 'said',\n",
       " 'that',\n",
       " 'the',\n",
       " 'place',\n",
       " 'will',\n",
       " 'be',\n",
       " 'fi',\n",
       " 'ed',\n",
       " 'but',\n",
       " 'not',\n",
       " 'done',\n",
       " 'Thanking',\n",
       " 'you',\n",
       " 'Yours',\n",
       " 'truly',\n",
       " 'Bhaskar',\n",
       " 'Mitra']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['modified_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42a356e3-ba50-426b-8898-e75c2d70a5f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['modified_text'] = [' '.join(row).lower() for row in df[\"modified_text\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3722fef-4de4-4a86-812f-9d1e63135b11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'railways railway board miscellaneous railway board zone psu pu office railway board railway board to the railway board sdah er location madhyamgram i further to informing you that the temporary railway line crossing near madhyamgram station bt end is in a very bad condition the stones on the side of the line have been moved far enough to cause great danger to the yrain common people and train passengers at any time please look at the matter although it was said that the place will be fi ed but not done thanking you yours truly bhaskar mitra'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['modified_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "544ce4b6-8cd9-4f18-afb2-21b28dbb509f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67dfb1d6-f69b-49f2-85e2-b102c0553a94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85b70143-b9ab-49c7-913d-cb05855b68b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    # iNPUT : IT WILL TAKE ROW/REVIEW AS AN INPUT\n",
    "    # take the paragraph, break into words, check if the word is a stop word, remove if stop word, combine the words into a para again\n",
    "    word = text.split()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    cleaned_text = \" \".join([i for i in word if i.lower() not in stop_words])\n",
    "    return cleaned_text\n",
    "df['modified_text'] = df['modified_text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4caaee8-19a4-4bb7-b2ab-1973bdcb36ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'railways railway board miscellaneous railway board zone psu pu office railway board railway board railway board sdah er location madhyamgram informing temporary railway line crossing near madhyamgram station bt end bad condition stones side line moved far enough cause great danger yrain common people train passengers time please look matter although said place fi ed done thanking truly bhaskar mitra'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['modified_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82a5dd50-8edf-466f-9872-04f937ad89e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab4d474a-93d4-4357-885e-b87252478c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\aravi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9e189a-6f80-4879-8f6a-c8e0faf211fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "def lemmatize_sentence(sentence):\n",
    "  # word tokenize -> pos tag (detailed) -> wordnet tag (shallow pos) -> lemmatizer -> root word\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  # output will be a list of tuples -> [(word,detailed_tag)]\n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged) # output -> [(word,shallow_tag)]\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:\n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "df['modified_text'] = df['modified_text'].apply(lambda x: lemmatize_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970316a-e2bd-4ce2-b480-1a7e8d8481af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['modified_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef27af48-04ef-47c9-9d92-18464de3e5b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "# Apply TF-IDF vectorization on the \"Description_edit\" column\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['modified_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cf5930-3505-4bae-b745-d3ba1a8dfc91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a69bf0e-492d-4e51-969c-e6e8bad4324d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaler = MaxAbsScaler()\n",
    "# Scale the sparse TF-IDF matrix\n",
    "tfidf_matrix_scaled = scaler.fit_transform(tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15cf246-4d3a-4fbc-b488-124703959066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tfidf_matrix_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c60c7e-9d09-4ee4-849f-d051ac3661f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "while True:\n",
    "    # Check for changes in the file containing user input\n",
    "    with open('user_input.txt', 'r') as f:\n",
    "        new_user_input = f.read().strip()\n",
    "    \n",
    "    # Check if user input has changed\n",
    "    if new_user_input:\n",
    "        text = new_user_input\n",
    "        with open('user_input.txt', 'w') as f:\n",
    "            f.write('')\n",
    "    \n",
    "    # Add a delay to avoid excessive CPU usage\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80daa948-e3be-4cfc-a3af-da02b741f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = clean_subject_content_text(text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c4a939-7aaf-41d0-92ed-a6c2b64c4e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = remove_punctuation(cleaned_text)\n",
    "print(clean_subject_content_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e575f-38c6-4c6a-9ba7-12a2c8ff32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize as wtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4911f76-0471-49af-a911-d5fd7a0c1620",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = wtk(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d87eeb-c0a9-46cb-b1ec-2741aa8f3bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c811aa-0d05-45b5-a897-2ea537a62117",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = [word.lower() for word in cleaned_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7faf221-cf8d-4f93-8705-5bf09c6522f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4d2a13-62c3-452c-bf7e-8eed1d2bb1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_text(word_list):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    cleaned_words = [word for word in word_list if word.lower() not in stop_words]\n",
    "    return cleaned_words\n",
    "\n",
    "cleaned_text = remove_stopwords_text(cleaned_text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bd0af8-b30b-4fa6-aeb5-dea9a3958acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = [lemmatizer.lemmatize(word) for word in cleaned_text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d7b82d-0b51-44fc-8c99-dde9e5f72e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_cleaned_text = tfidf_vectorizer.fit_transform(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f93b723-fdc7-4b51-8023-1c6cdead98c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf_matrix_cleaned_text_scalar = scaler.fit_transform(tfidf_matrix_cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5824ef-0689-4afd-a1a7-70efb8fc1f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tfidf_matrix_cleaned_text_scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0cecc3-1479-41d1-ae42-1d4723c8881a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cos_similarities = cosine_similarity(tfidf_matrix_cleaned_text_scalar, tfidf_matrix_cleaned_text)\n",
    "\n",
    "# Get the index of the top N similar texts\n",
    "N = 10  # Adjust as needed\n",
    "top_similar_indices = cos_similarities.argsort()[0][-N:][::-1]\n",
    "\n",
    "# Retrieve the top N similar texts from the DataFrame based on the indices\n",
    "top_similar_texts = df.iloc[top_similar_indices]\n",
    "\n",
    "# Print or further process top_similar_texts\n",
    "print(top_similar_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a1019c-9ca4-4fc3-b076-e41635889eec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_res =top_similar_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ed06f-0da9-42ba-842c-6a64688d0fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c801932-3ebb-47c1-99a5-77f0d278a319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['subject_content_text'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2687c3-5980-463d-926e-b39deca12632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_action = pd.read_json(\"C:\\\\Users\\\\aravi\\\\OneDrive\\\\Documents\\\\problem_statement_1_and_2\\\\no_pii_action_history\\\\no_pii_action_history.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf1c2b-617c-4f2a-be76-210e1ac75b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_action, df_res, on='registration_no', how='left')\n",
    "# Iterate through the merged DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming merged_df is the merged DataFrame containing both df and df_action data\n",
    "# Assuming 'officer_detail' is the column representing the details of the officer\n",
    "\n",
    "# Filter out rows where 'officer_detail' is not None\n",
    "merged_df = merged_df.dropna(subset=['OfficerDetail'])\n",
    "\n",
    "# Now you can proceed with further processing on filtered_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84459e9-7361-442d-8589-d465dc2f2e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Redirect complaint to the: ' + merged_df['OfficerDetail'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2295d651-2e1c-4ba3-a511-3382beb9b03d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dc9f9d-16b7-43c0-9a92-b9f9b0679894",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(df, open('raw_data_set.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b2110-404a-4453-9fa0-271a360027a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
